{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1pSHRwoOIAVg"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, roc_auc_score\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from transformers import BertTokenizer, TFBertForSequenceClassification, AdamWeightDecay\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "file_path = '/mnt/data/bot_detection_data.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "\n",
        "texts = df['Tweet'].astype(str).values\n",
        "labels = df['Bot Label'].values\n",
        "\n",
        "\n",
        "texts_train, texts_test, y_train, y_test = train_test_split(texts, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"Treinando Logistic Regression com TF-IDF...\")\n",
        "\n",
        "tfidf = TfidfVectorizer(max_features=1000)\n",
        "X_train_tfidf = tfidf.fit_transform(texts_train)\n",
        "X_test_tfidf = tfidf.transform(texts_test)\n",
        "\n",
        "lr_model = LogisticRegression(class_weight='balanced', max_iter=1000)\n",
        "lr_model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "y_pred_lr = lr_model.predict(X_test_tfidf)\n",
        "\n",
        "print(\"Logistic Regression Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_lr))\n",
        "\n",
        "auc_lr = roc_auc_score(y_test, y_pred_lr)\n",
        "print(f'Logistic Regression AUC: {auc_lr}\\n')\n",
        "\n",
        "print(\"Treinando modelo BERT...\")\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "def tokenize_data(texts, max_len=128):\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "\n",
        "    for text in texts:\n",
        "        encoded = tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=max_len,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='tf'\n",
        "        )\n",
        "        input_ids.append(encoded['input_ids'])\n",
        "        attention_masks.append(encoded['attention_mask'])\n",
        "\n",
        "    return tf.concat(input_ids, axis=0), tf.concat(attention_masks, axis=0)\n",
        "\n",
        "input_ids_train, attention_masks_train = tokenize_data(texts_train)\n",
        "input_ids_test, attention_masks_test = tokenize_data(texts_test)\n",
        "\n",
        "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
        "class_weights_dict = {i: class_weights[i] for i in range(len(class_weights))}\n",
        "print(\"Class weights:\", class_weights_dict)\n",
        "\n",
        "bert_model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
        "\n",
        "optimizer = AdamWeightDecay(learning_rate=2e-5)\n",
        "bert_model.compile(optimizer=optimizer, loss=bert_model.compute_loss, metrics=['accuracy'])\n",
        "\n",
        "history = bert_model.fit(\n",
        "    [input_ids_train, attention_masks_train],\n",
        "    y_train,\n",
        "    validation_data=([input_ids_test, attention_masks_test], y_test),\n",
        "    epochs=3,\n",
        "    batch_size=16,\n",
        "    class_weight=class_weights_dict\n",
        ")\n",
        "\n",
        "print(\"Avaliando o modelo BERT...\")\n",
        "\n",
        "test_logits = bert_model.predict([input_ids_test, attention_masks_test]).logits\n",
        "y_pred_bert = tf.argmax(test_logits, axis=1)\n",
        "\n",
        "print(\"BERT Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_bert))\n",
        "\n",
        "auc_bert = roc_auc_score(y_test, y_pred_bert)\n",
        "print(f'BERT AUC: {auc_bert}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Descrição das Etapas:\n",
        "Carregamento e Pré-processamento dos Dados:\n",
        "\n",
        "Objetivo: Carregar o dataset de tweets e dividir os dados entre treino e teste.\n",
        "Descrição: Os textos dos tweets e seus respectivos rótulos (bots ou não bots) são extraídos do dataset. Em seguida, os dados são divididos em conjuntos de treino e teste usando o train_test_split, para garantir que possamos avaliar o modelo posteriormente em dados que ele não viu durante o treinamento.\n",
        "Logistic Regression com TF-IDF:\n",
        "\n",
        "Objetivo: Treinar um modelo mais simples de classificação (Logistic Regression) para comparação com o BERT.\n",
        "Descrição: A etapa transforma os textos dos tweets em vetores de frequência de termos inversamente ponderados por frequência no documento (TF-IDF), que capturam a importância das palavras nos textos. Com esses vetores, o modelo Logistic Regression é treinado para classificar os tweets. A avaliação deste modelo é realizada usando métricas como precisão, recall, F1 Score e AUC, que medem a capacidade do modelo de identificar corretamente os bots.\n",
        "Tokenização com BERT Tokenizer:\n",
        "\n",
        "Objetivo: Preparar os dados para o modelo BERT.\n",
        "Descrição: O BERT exige que os textos sejam convertidos em uma sequência de IDs de tokens, além de máscaras de atenção para lidar com padding. A função tokenizer.encode_plus é usada para tokenizar e gerar essas sequências e máscaras de atenção. Essas representações tokenizadas são usadas como entradas para o modelo BERT.\n",
        "Rebalanceamento das Classes:\n",
        "\n",
        "Objetivo: Ajustar o modelo para lidar com o desbalanceamento de classes (bots vs. não bots).\n",
        "Descrição: O dataset pode ter um desbalanceamento, com mais exemplos de uma classe do que da outra (como mais tweets de bots do que de não bots, ou vice-versa). Para contornar isso, calculamos os pesos das classes com compute_class_weight, e esses pesos são aplicados durante o treinamento para garantir que o modelo não favoreça excessivamente a classe majoritária.\n",
        "Treinamento do Modelo BERT:\n",
        "\n",
        "Objetivo: Treinar um modelo BERT para a classificação de tweets em bots e não bots.\n",
        "Descrição: Utilizando o modelo pré-treinado TFBertForSequenceClassification, treinamos o modelo BERT com os dados tokenizados. O modelo é ajustado com a técnica de AdamWeightDecay para otimização e os pesos de classe são aplicados para lidar com o desbalanceamento. O treinamento é realizado por 3 épocas, com validação nos dados de teste em cada época.\n",
        "Avaliação do Modelo BERT:\n",
        "\n",
        "Objetivo: Avaliar o desempenho do modelo BERT treinado.\n",
        "Descrição: Após o treinamento, o modelo BERT é avaliado nos dados de teste. Utilizamos as previsões do modelo para calcular métricas de classificação, incluindo precisão (quantos bots foram corretamente identificados), recall (quantos bots o modelo conseguiu identificar), F1 Score (um equilíbrio entre precisão e recall), e AUC (que mede a capacidade do modelo de separar as classes).\n"
      ],
      "metadata": {
        "id": "t7tXu8CyItLd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Análise dos Resultados:\n",
        "Modelo Logistic Regression:\n",
        "\n",
        "Desempenho: O modelo Logistic Regression, que é mais simples, serve como uma referência para o desempenho em relação ao BERT. Ele pode ter um desempenho razoável em conjuntos de dados menores ou com pouca complexidade linguística. Ao avaliar as métricas como precisão, recall e AUC, podemos ver como esse modelo se sai em relação ao modelo BERT.\n",
        "Comparação com BERT: Se o modelo Logistic Regression tiver métricas comparáveis ou melhores que o BERT, pode sugerir que o BERT está subutilizando os dados ou que o problema pode ser resolvido com um modelo mais simples.\n",
        "Modelo BERT:\n",
        "\n",
        "Desempenho: O BERT é projetado para capturar nuances linguísticas e contextos complexos em textos, o que o torna ideal para tarefas como classificação de tweets. No entanto, devido à sua complexidade, ele pode exigir um ajuste mais cuidadoso (como o número de épocas, taxas de aprendizado e rebalanceamento de classes). A avaliação de precisão, recall e F1 Score nos ajuda a entender se o modelo está conseguindo distinguir corretamente entre bots e não bots.\n",
        "Impacto do Rebalanceamento: O uso de pesos de classe durante o treinamento pode ter um impacto significativo, especialmente em datasets desbalanceados. Se o desempenho do modelo em detectar a classe minoritária (provavelmente \"não bots\") melhorar após o rebalanceamento, isso indicaria que o modelo está aprendendo a dar mais importância para essa classe.\n",
        "AUC (Área Sob a Curva ROC):\n",
        "\n",
        "AUC para Logistic Regression: O AUC mostra a capacidade do modelo Logistic Regression em separar as duas classes. Um AUC de 0,5 indicaria que o modelo não tem discriminação entre bots e não bots, enquanto um valor próximo de 1 indica uma separação perfeita.\n",
        "AUC para BERT: Da mesma forma, a AUC para o BERT mostra sua capacidade de discriminar entre as duas classes. Como o BERT é um modelo mais sofisticado, esperamos que o AUC seja superior ao do modelo Logistic Regression, assumindo que o modelo BERT foi ajustado adequadamente.\n"
      ],
      "metadata": {
        "id": "0VoYHjl4JFeW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Próximos Passos:\n",
        "Ajustes de Hiperparâmetros:\n",
        "\n",
        "O número de épocas, o tamanho do lote, e a taxa de aprendizado podem ser ajustados para melhorar o desempenho do modelo BERT. Aumentar o número de épocas ou testar diferentes valores de taxa de aprendizado pode resultar em melhor desempenho.\n",
        "Engenharia de Features:\n",
        "\n",
        "Adicionar features adicionais além do texto pode melhorar o desempenho. Por exemplo, a contagem de seguidores, retweets, ou a presença de links no tweet podem ajudar o modelo a detectar padrões que distinguem bots de não bots.\n",
        "Tuning dos Pesos das Classes:\n",
        "\n",
        "Continuar experimentando com diferentes formas de balanceamento de classes pode ajudar a encontrar um ponto de equilíbrio que melhore tanto a precisão quanto o recall para as classes minoritárias.\n",
        "Comparação com Outros Modelos:\n",
        "\n",
        "Experimente outros modelos de linguagem pré-treinados, como RoBERTa ou DistilBERT, que podem ser mais rápidos ou mais eficientes que o BERT padrão, sem sacrificar tanto o desempenho."
      ],
      "metadata": {
        "id": "q362-_uzI9ZH"
      }
    }
  ]
}